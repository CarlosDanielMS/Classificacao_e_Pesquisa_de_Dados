# ğŸ–¥ï¸ CPD - Trabalho PrÃ¡tico 1 - Crawler de Busca

Este repositÃ³rio contÃ©m um projeto prÃ¡tico desenvolvido como parte da disciplina de CPD. O objetivo do trabalho Ã© criar um **crawler** ğŸ“¡ para buscar dados de um site de e-commerce e ordenar os produtos coletados por **ordem crescente de preÃ§o** ğŸ’¸. A implementaÃ§Ã£o inclui a utilizaÃ§Ã£o BubbleSort de ordenaÃ§Ã£o estudado ao longo da cadeira e uma versÃ£o pra trabalhar com externo.

## ğŸ“Œ DescriÃ§Ã£o do Projeto

O projeto Ã© dividido em trÃªs partes principais:

1. **Coleta de Dados** ğŸ“Š: UtilizaÃ§Ã£o de um crawler para extrair informaÃ§Ãµes dos produtos.
2. **OrdenaÃ§Ã£o dos Produtos** ğŸ”„: AplicaÃ§Ã£o de um algoritmo de ordenaÃ§Ã£o para ordenar a lista de produtos em ordem crescente de preÃ§o.
3. **OrdenaÃ§Ã£o Externa (Opcional)** ğŸ’¾: ImplementaÃ§Ã£o de um algoritmo de ordenaÃ§Ã£o externa para grandes volumes de dados que nÃ£o cabem na memÃ³ria.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem de ProgramaÃ§Ã£o**: Python & HTML
- **Bibliotecas**:
  - **Requests**: Para realizar requisiÃ§Ãµes HTTP e obter o HTML das pÃ¡ginas.
  - **BeautifulSoup**: Para fazer o parsing do HTML e extrair os dados necessÃ¡rios.
  - **Flask**: Para criar uma interface web e permitir a interaÃ§Ã£o com o script.

## ğŸ“‚ Estrutura do RepositÃ³rio

- **ğŸ“„ app.py**: Script contendo a aplicaÃ§Ã£o Flask para criar uma interface web para o projeto.
- **ğŸ“‘ README.md**: DocumentaÃ§Ã£o do projeto, incluindo instruÃ§Ãµes de uso e descriÃ§Ã£o dos objetivos.
- **ğŸ“¦ requirements.txt**: Lista de dependÃªncias para instalar as bibliotecas necessÃ¡rias.
- **ğŸ“‚ templates**:
  - **ğŸ“„ index.html**: PÃ¡gina inicial para iniciar o scraping.
  - **ğŸ“„ results.html**: PÃ¡gina de resultados para exibir os produtos ordenados.

## ğŸš€ ExecuÃ§Ã£o do Projeto

Para executar o projeto localmente, siga as instruÃ§Ãµes abaixo:

1. **Clone o repositÃ³rio**:
   
sh
   git clone <link_do_repositorio>

2. **Instale as dependÃªncias**:
   
sh
   pip install -r requirements.txt

3. **Execute a aplicaÃ§Ã£o Flask**:
   
sh
   python app.py


## ğŸ‘¥ Colaboradores

- **ğŸ‘¤ Brayan Martins**
- **ğŸ‘¤ Carlos Daniel Martins**

## ğŸ“¢ ObservaÃ§Ã£o

DuraÃ§Ã£o de 5 a 10 minutos, abordando as seguintes etapas: site utilizado, algoritmo de ordenaÃ§Ã£o escolhido, justificativa das escolhas e resultados obtidos.

## ğŸ“ OrganizaÃ§Ã£o

- **Notion**: [Link para a organizaÃ§Ã£o do projeto](https://www.notion.so/CPD-TRABALHO-cb9ead442bc34965897eefdf3d5bee80?pvs=4)

## ğŸ’¡ Interface do UsuÃ¡rio

- **PÃ¡gina Inicial**: O usuÃ¡rio pode escolher de qual site deseja buscar os produtos (laptops, tablets, telefones).
- **Resultados**: Exibe os produtos encontrados, seus preÃ§os e, em uma seÃ§Ã£o separada, informaÃ§Ãµes sobre itens que nÃ£o foram capturados corretamente ou que apresentaram erros.

## ğŸ”— Sites utilizados

- [Books to Scrape](http://books.toscrape.com)
- [Craigslist](https://bn.craigslist.org/search/ata#search=1~gallery~0~0)

## ğŸ“„ Documentos Utilizados

- [DocumentaÃ§Ã£o do BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc)
- [DocumentaÃ§Ã£o do Requests](https://requests.readthedocs.io/en/latest/)
- [DocumentaÃ§Ã£o do Flask](https://flask.palletsprojects.com/en/3.0.x/)
- [OrdenaÃ§Ã£o Externa](https://www.geeksforgeeks.org/external-sorting/)
- [HTML](https://developer.mozilla.org/en-US/docs/Web/HTML)

## ğŸ¥ Video

- [CPD - TRABALHO CRAWLER](https://youtu.be/I2O1biixYlI)
